{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPuV9XwUO0MQtX/t3gIfvdw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shrutikpawale18/Similarity_Measure/blob/main/SimilarityMeasure.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math"
      ],
      "metadata": {
        "id": "krVtltTkyyuj"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "gFPkjL6_TTDz"
      },
      "outputs": [],
      "source": [
        "#Change the sentences accordingly\n",
        "\n",
        "text_1 = f\"The easiest way to earn points with Fetch Rewards is to just shop for the products you already love. If you have any participating brands on your receipt, you'll get points based on the cost of the products. You don't need to clip any coupons or scan individual barcodes. Just scan each grocery receipt after you shop and we'll find the savings for you.\"\n",
        "\n",
        "text_2 = f\"The easiest way to earn points with Fetch Rewards is to just shop for the items you already buy. If you have any eligible brands on your receipt, you will get points based on the total cost of the products. You do not need to cut out any coupons or scan individual UPCs. Just scan your receipt after you check out and we will find the savings for you.\"\n",
        "\n",
        "text_3 = f\"We are always looking for opportunities for you to earn more points, which is why we also give you a selection of Special Offers. These Special Offers are opportunities to earn bonus points on top of the regular points you earn every time you purchase a participating brand. No need to pre-select these offers, we'll give you the points whether or not you knew about the offer. We just think it is easier that way.\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "class TFIDFVectorizer:\n",
        "    def __init__(self, *texts):\n",
        "        # Tokenize texts into words and store in documents\n",
        "        self.documents = [self.text_to_words(text) for text in texts]\n",
        "\n",
        "        # Calculate TF for each document\n",
        "        self.tf_dicts = [self.calculate_tf(doc) for doc in self.documents]\n",
        "\n",
        "        # Calculate IDF for all documents\n",
        "        self.idf_dict = self.calculate_idf(self.documents)\n",
        "\n",
        "        # Calculate TF-IDF vectors for each document\n",
        "        self.tfidf_vectors = [self.vectorize(doc, self.idf_dict) for doc in self.tf_dicts]\n",
        "\n",
        "    def text_to_words(self, text):\n",
        "        # Tokenize text into words\n",
        "        words = []\n",
        "        current_word = ''\n",
        "        for char in text:\n",
        "            if char != \" \":\n",
        "                current_word += char\n",
        "            else:\n",
        "                words.append(current_word.lower())\n",
        "                current_word = ''\n",
        "        words.append(current_word.lower())  # Append the last word\n",
        "        return words\n",
        "\n",
        "    def calculate_tf(self, words):\n",
        "        # Calculate Term Frequency (TF) for a document\n",
        "        word_count = {}\n",
        "        tf_dict = {}\n",
        "\n",
        "        for word in words:\n",
        "            if word_count.get(word):\n",
        "                word_count[word] += 1\n",
        "            else:\n",
        "                word_count[word] = 1\n",
        "\n",
        "        total_words = len(words)\n",
        "        for word, count in word_count.items():\n",
        "            tf_dict[word] = count / total_words\n",
        "        return tf_dict\n",
        "\n",
        "    def calculate_idf(self, documents):\n",
        "        # Calculate Inverse Document Frequency (IDF) for all documents\n",
        "        total_documents = len(documents)\n",
        "        word_document_count = {}\n",
        "        idf_dict = {}\n",
        "\n",
        "        for document in documents:\n",
        "            for word in set(document):\n",
        "                if word_document_count.get(word):\n",
        "                    word_document_count[word] += 1\n",
        "                else:\n",
        "                    word_document_count[word] = 1\n",
        "\n",
        "        for word, count in word_document_count.items():\n",
        "            idf_dict[word] = math.log(total_documents / count)\n",
        "        return idf_dict\n",
        "\n",
        "    def vectorize(self, tf_dict, idf_dict):\n",
        "        # Calculate TF-IDF vector for a document\n",
        "        tfidf = []\n",
        "        for word in tf_dict:\n",
        "            tfidf.append(tf_dict[word] * idf_dict[word])\n",
        "        return tfidf\n",
        "\n",
        "\n",
        "tfidf_vectorizer = TFIDFVectorizer(text_1, text_2, text_3)\n",
        "\n",
        "# Access TF-IDF vectors for each text\n",
        "tfidf_text1 = tfidf_vectorizer.tfidf_vectors[0]\n",
        "tfidf_text2 = tfidf_vectorizer.tfidf_vectors[1]\n",
        "tfidf_text3 = tfidf_vectorizer.tfidf_vectors[2]"
      ],
      "metadata": {
        "id": "eMwxurRFTTqb"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "class CosineSimilarity:\n",
        "    def __init__(self, vec1, vec2):\n",
        "        # Initialize with two vectors for which cosine similarity will be calculated\n",
        "        self.vec1 = vec1\n",
        "        self.vec2 = vec2\n",
        "\n",
        "    def dot_product(self):\n",
        "        # Calculate the dot product of the two vectors\n",
        "        return sum(x * y for x, y in zip(self.vec1, self.vec2))\n",
        "\n",
        "    def magnitude(self, vec):\n",
        "        # Calculate the magnitude of a vector\n",
        "        return math.sqrt(sum(x ** 2 for x in vec))\n",
        "\n",
        "    def calculate_similarity(self):\n",
        "        # Calculate the cosine similarity between the two vectors\n",
        "        dot_prod = self.dot_product()\n",
        "        mag_vec1 = self.magnitude(self.vec1)\n",
        "        mag_vec2 = self.magnitude(self.vec2)\n",
        "\n",
        "        if mag_vec1 == 0 or mag_vec2 == 0:\n",
        "            return 0  # To handle division by zero\n",
        "\n",
        "        return dot_prod / (mag_vec1 * mag_vec2)\n",
        "\n",
        "\n",
        "# Create instances of CosineSimilarity\n",
        "cosine_similarity_1_2 = CosineSimilarity(tfidf_text1, tfidf_text2)\n",
        "cosine_similarity_1_3 = CosineSimilarity(tfidf_text1, tfidf_text3)\n",
        "\n",
        "# Calculate cosine similarity\n",
        "similarity_1_2 = cosine_similarity_1_2.calculate_similarity()\n",
        "similarity_1_3 = cosine_similarity_1_3.calculate_similarity()\n",
        "\n",
        "# Print the similarity\n",
        "print(f\"Similarity between sentences 1 and 2: {round(similarity_1_2,2)}\")\n",
        "print(f\"Similarity between sentences 1 and 3: {round(similarity_1_3,2)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yo29qS7JTVEB",
        "outputId": "f870f0d8-4aa6-45fa-e02e-a209a1720e36"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity between sentences 1 and 2: 0.74\n",
            "Similarity between sentences 1 and 3: 0.63\n"
          ]
        }
      ]
    }
  ]
}